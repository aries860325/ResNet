{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_init_2_.ipynb","version":"0.3.2","provenance":[{"file_id":"1VL1sK4Hz_IsuhkyQRc8h2SD3w90OF1yp","timestamp":1526642217104}],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"gX3SX-Y5Kh1A","colab":{}},"source":["# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","# !apt-get update -qq 2>&1 > /dev/null\n","# !apt-get -y install -qq google-drive-ocamlfuse fuse\n","# from google.colab import auth\n","# auth.authenticate_user()\n","# from oauth2client.client import GoogleCredentials\n","# creds = GoogleCredentials.get_application_default()\n","# import getpass\n","# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","# vcode = getpass.getpass()\n","# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","\n","\n","# !mkdir -p drive\n","\n","# !google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9OfzEvz5tlzb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"0cc26089-6fde-4ef2-d005-2ce18b7b4c98","executionInfo":{"status":"ok","timestamp":1563376317588,"user_tz":-480,"elapsed":5177,"user":{"displayName":"洪慶豪","photoUrl":"","userId":"16984441900942616082"}}},"source":["# !unzip -q drive/20190704/images.zip\n","!ls"],"execution_count":10,"outputs":[{"output_type":"stream","text":["adc.json     test.txt\n","checkpoint   tf_resnet_model_iter15001.ckpt.data-00000-of-00001\n","drive\t     tf_resnet_model_iter15001.ckpt.index\n","images\t     tf_resnet_model_iter15001.ckpt.meta\n","log2\t     train.txt\n","sample_data  val.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WhHNDXvWYI5R"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hr6uu3lMzh0M","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python.training.moving_averages import assign_moving_average\n","import numpy as np\n","import os, pdb\n","import cv2\n","import numpy as np\n","import random as rn\n","import tensorflow as tf\n","import threading\n","import time\n","\n","global n_classes, ema_gp\n","ema_gp = []\n","n_classes = 50\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zyjBt-MqVce6","colab":{}},"source":["\n","def activation(x,name=\"activation\"):\n","    return tf.nn.relu(x, name=name)\n","    \n","def conv2d(name, l_input, w, b, s, p):\n","    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n","    l_input = l_input+b\n","\n","    return l_input\n","\n","def batchnorm(conv, isTraining, name='bn'):\n","    return tf.layers.batch_normalization(conv, training=isTraining, name=\"bn\"+name)\n","\n","def initializer(in_filters, out_filters, name):\n","    w1 = tf.get_variable(name+\"W\", [3, 3, in_filters, out_filters], initializer=tf.truncated_normal_initializer())\n","    b1 = tf.get_variable(name+\"B\", [out_filters], initializer=tf.truncated_normal_initializer())\n","    return w1, b1\n","  \n","def residual_block(in_x, in_filters, out_filters, stride, isDownSampled, name, isTraining):\n","    global ema_gp\n","    # first convolution layer\n","    if isDownSampled:\n","      in_x = tf.nn.avg_pool(in_x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n","      \n","    x = batchnorm(in_x, isTraining, name=name+'FirstBn')\n","    x = activation(x)\n","    w1, b1 = initializer(in_filters, in_filters, name+\"first_res\")\n","    x = conv2d(name+'r1', x, w1, b1, 1, \"SAME\")\n","\n","    # second convolution layer\n","    x = batchnorm(x, isTraining, name=name+'SecondBn')\n","    x = activation(x)\n","    w2, b2 = initializer(in_filters, out_filters, name+\"Second_res\")\n","    x = conv2d(name+'r2', x, w2, b2, 1, \"SAME\")\n","    \n","    if in_filters != out_filters:\n","        difference = out_filters - in_filters\n","        left_pad = difference // 2\n","        right_pad = difference - left_pad\n","        identity = tf.pad(in_x, [[0, 0], [0, 0], [0, 0], [left_pad, right_pad]])\n","        return x + identity\n","    else:\n","        return in_x + x\n","\n","      \n","def ResNet(_X, isTraining):\n","    global n_classes\n","    w1 = tf.get_variable(\"initW\", [7, 7, 3, 96], initializer=tf.truncated_normal_initializer())\n","    b1 = tf.get_variable(\"initB\", [96], initializer=tf.truncated_normal_initializer())\n","    x = conv2d('conv1', _X, w1, b1, 4, \"VALID\")\n","    \n","    filters_num = [96,128,256,384]\n","    block_num = [2,2,2,2]\n","    l_cnt = 1\n","    for i in range(len(filters_num)):\n","      for j in range(block_num[i]):\n","          \n","          if ((j==block_num[i]-1) & (i<len(filters_num)-1)):\n","            x = residual_block(x, filters_num[i], filters_num[i+1], 2, True, 'ResidualBlock%d'%(l_cnt), isTraining)\n","            print('[L-%d] Build %dth connection layer %d from %d to %d channels' % (l_cnt, i, j, filters_num[i], filters_num[i+1]))\n","          else:\n","            x = residual_block(x, filters_num[i], filters_num[i], 1, False, 'ResidualBlock%d'%(l_cnt), isTraining)\n","            print('[L-%d] Build %dth residual block %d with %d channels' % (l_cnt,i, j, filters_num[i]))\n","          l_cnt +=1\n","\n","    \n","    wo, bo=initializer(filters_num[-1], n_classes, \"FinalOutput\")\n","    x = conv2d('final', x, wo, bo, 1, \"SAME\")\n","    \n","    x = activation(x)\n","    x = batchnorm(x, isTraining, name='FinalBn')\n","    \n","    x = tf.reduce_mean(x, [1,2])\n","    W = tf.get_variable(\"FinalW\", [n_classes, n_classes], initializer=tf.truncated_normal_initializer())\n","    b = tf.get_variable(\"FinalB\", [n_classes], initializer=tf.truncated_normal_initializer())\n","    \n","    out = tf.matmul(x, W) + b\n","                            \n","\n","    return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tCNUC9U1zh0U","colab":{}},"source":["#==========================================================================\n","#=============Reading data in multithreading manner========================\n","#==========================================================================\n","def read_labeled_image_list(image_list_file, training_img_dir):\n","    \"\"\"Reads a .txt file containing pathes and labeles\n","    Args:\n","       image_list_file: a .txt file with one /path/to/image per line\n","       label: optionally, if set label will be pasted after each line\n","    Returns:\n","       List with all filenames in file image_list_file\n","    \"\"\"\n","    f = open(image_list_file, 'r')\n","    filenames = []\n","    labels = []\n","\n","    for line in f:\n","        filename, label = line[:-1].split(' ')\n","        filename = training_img_dir+filename\n","        filenames.append(filename)\n","        labels.append(int(label))\n","        \n","    return filenames, labels\n","    \n","    \n","def read_images_from_disk(input_queue, size1=256):\n","    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n","    Args:\n","      filename_and_label_tensor: A scalar string tensor.\n","    Returns:\n","      Two tensors: the decoded image, and the string label.\n","    \"\"\"\n","    label = input_queue[1]\n","    fn=input_queue[0]\n","    file_contents = tf.read_file(input_queue[0])\n","    example = tf.image.decode_jpeg(file_contents, channels=3)\n","    \n","    #example = tf.image.decode_png(file_contents, channels=3, name=\"dataset_image\") # png fo rlfw\n","    example=tf.image.resize_images(example, [size1,size1])\n","    return example, label, fn\n","    \n","def setup_inputs(sess, filenames, training_img_dir, image_size=256, crop_size=224, isTest=False, batch_size=128):\n","    \n","    # Read each image file\n","    image_list, label_list = read_labeled_image_list(filenames, training_img_dir)\n","\n","    images = tf.cast(image_list, tf.string)\n","    labels = tf.cast(label_list, tf.int64)\n","     # Makes an input queue\n","    if isTest is False:\n","        isShuffle = True\n","        numThr = 4\n","    else:\n","        isShuffle = False\n","        numThr = 1\n","        \n","    input_queue = tf.train.slice_input_producer([images, labels], shuffle=isShuffle)\n","    image, y,fn = read_images_from_disk(input_queue)\n","\n","    channels = 3\n","    image.set_shape([None, None, channels])\n","        \n","    # Crop and other random augmentations\n","    if isTest is False:\n","        image = tf.image.random_flip_left_right(image)\n","        image = tf.image.random_saturation(image, .95, 1.05)\n","        image = tf.image.random_brightness(image, .05)\n","        image = tf.image.random_contrast(image, .95, 1.05)\n","        \n","\n","    image = tf.random_crop(image, [crop_size, crop_size, 3])\n","    image = tf.cast(image, tf.float32)/255.0\n","    \n","    image, y,fn = tf.train.batch([image, y, fn], batch_size=batch_size, capacity=batch_size*3, num_threads=numThr, name='labels_and_images')\n","\n","    tf.train.start_queue_runners(sess=sess)\n","\n","    return image, y, fn, len(label_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h7AtFd4czh0W","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e1342bb0-27ed-4dfc-d8ad-e366cf514007","executionInfo":{"status":"ok","timestamp":1563376318212,"user_tz":-480,"elapsed":5745,"user":{"displayName":"洪慶豪","photoUrl":"","userId":"16984441900942616082"}}},"source":["batch_size = 256\n","display_step = 80\n","learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n","lr = 1e-2                          # Learning rate start\n","print('GO!!')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["GO!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7LCc7xsQzh0Y","colab":{"base_uri":"https://localhost:8080/","height":393},"outputId":"973a58ba-0939-4cc7-8ebd-9f14431ab093","executionInfo":{"status":"error","timestamp":1563376318567,"user_tz":-480,"elapsed":6089,"user":{"displayName":"洪慶豪","photoUrl":"","userId":"16984441900942616082"}}},"source":["# Setup the tensorflow...\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.Session(config=config)\n","\n","print(\"Preparing the training & validation data...\")\n","train_data, train_labels, filelist1, glen1 = setup_inputs(sess, \"train.txt\", \"./\", batch_size=batch_size)\n","val_data, val_labels, filelist2, tlen1 = setup_inputs(sess, \"val.txt\", \"./\", batch_size=batch_size,isTest=True)\n","\n","\n","max_iter = glen1*100\n","print(\"Preparing the training model with learning rate = %.5f...\" % (lr))\n","\n","\n","with tf.variable_scope(\"ResNet\") as scope:\n","  pred = ResNet(train_data, True)\n","  scope.reuse_variables()\n","  valpred = ResNet(val_data, False)\n","\n","with tf.name_scope('Loss_and_Accuracy'):\n","  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","  with tf.control_dependencies(update_ops):\n","    cost = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=pred)\n","    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n","    \n","  correct_prediction = tf.equal(tf.argmax(pred, 1), train_labels)\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  top5=tf.reduce_mean(tf.cast(tf.nn.in_top_k(pred, train_labels, 5), tf.float32))\n","  \n","  correct_prediction2 = tf.equal(tf.argmax(valpred, 1), val_labels)\n","  accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n","  \n","  tf.summary.scalar('Loss', cost)\n","  tf.summary.scalar('Training_Accuracy', accuracy)\n","  tf.summary.scalar('Top-5_accuracy', top5)\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Preparing the training & validation data...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8c5cbbcb816e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preparing the training & validation data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilelist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilelist2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0misTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-fbefbd28a462>\u001b[0m in \u001b[0;36msetup_inputs\u001b[0;34m(sess, filenames, training_img_dir, image_size, crop_size, isTest, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_labeled_image_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_img_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m      \u001b[0;31m# Makes an input queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m   \u001b[0minferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_from_nested_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;31m# We did not find any tensor-like objects in the nested lists, so defer to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_get_dtype_from_nested_lists\u001b[0;34m(list_or_tuple)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m       \u001b[0mmaybe_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_from_nested_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmaybe_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CGfQ_Cbzh0c","colab":{}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","step = 0\n","writer = tf.summary.FileWriter(\"log2\", sess.graph)\n","summaries = tf.summary.merge_all()\n","\n","print(\"We are going to train the ImageNet model based on ResNet!!!\")\n","while (step * batch_size) < max_iter:\n","    epoch1=np.floor((step*batch_size)/glen1)\n","    if (((step*batch_size)%glen1 < batch_size) & (lr==1e-3) & (epoch1 >2)):\n","        lr /= 10\n","\n","    sess.run(optimizer,  feed_dict={learning_rate: lr})\n","\n","    if (step % 15000==1) & (step>15000):\n","        save_path = saver.save(sess, \"./tf_resnet_model_iter\" + str(step) + \".ckpt\")\n","        print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n","\n","    if step>1 and step % display_step == 1:\n","        # calculate the loss\n","        loss, acc, top5acc, summaries_string = sess.run([cost, accuracy,top5, summaries])\n","        print(\"Iter=%d/epoch=%d, Loss=%.6f, Training Accuracy=%.6f, Top-5 Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, acc, top5acc, lr))\n","        writer.add_summary(summaries_string, step)\n","        \n","    if step>1 and (step % (display_step*10) == 1):\n","        rounds = tlen1 // batch_size\n","        valacc=[]\n","        for k in range(rounds):\n","          a2 = sess.run(accuracy2)\n","          valacc.append(a2)\n","        print(\"\\nIter=%d/epoch=%d, Validation Accuracy=%.6f\" % (step*batch_size, epoch1 , np.mean(valacc)))\n","\n","  \n","    step += 1\n","print(\"Optimization Finished!\")\n","save_path = saver.save(sess, \"./tf_resnet_model.ckpt\")\n","print(\"Model saved in file: %s\" % save_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eCjuZ3163ZOr"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AOQOeejKzh0f","colab":{}},"source":["exit()"],"execution_count":0,"outputs":[]}]}